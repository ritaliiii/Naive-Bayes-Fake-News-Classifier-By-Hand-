{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NjcaSjyZBJwx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "df_real = pd.read_csv('True.csv')\n",
        "df_real['RealNews?'] = True\n",
        "\n",
        "df_fake = pd.read_csv('Fake.csv')\n",
        "df_fake['RealNews?'] = False\n",
        "\n",
        "# Combine data together\n",
        "df = pd.concat([df_real, df_fake], ignore_index=True)\n",
        "\n",
        "# Create a new column called documen containing info [title + text]\n",
        "df['document'] = df[['title', 'text']].agg(' '.join, axis=1)\n",
        "# Ignore the cases for symplicity\n",
        "df['document'] = df['document'].apply(lambda x: x.lower())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the head and the length of the dataset\n",
        "print(df.head())\n",
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC8dAKy2HnJm",
        "outputId": "f6e4ccb6-312f-43dd-ea12-4dbc57b1d925"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0  As U.S. budget fight looms, Republicans flip t...   \n",
            "1  U.S. military to accept transgender recruits o...   \n",
            "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
            "3  FBI Russia probe helped by Australian diplomat...   \n",
            "4  Trump wants Postal Service to charge 'much mor...   \n",
            "\n",
            "                                                text       subject  \\\n",
            "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
            "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
            "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
            "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
            "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
            "\n",
            "                 date  RealNews?  \\\n",
            "0  December 31, 2017        True   \n",
            "1  December 29, 2017        True   \n",
            "2  December 31, 2017        True   \n",
            "3  December 30, 2017        True   \n",
            "4  December 29, 2017        True   \n",
            "\n",
            "                                            document  \n",
            "0  as u.s. budget fight looms, republicans flip t...  \n",
            "1  u.s. military to accept transgender recruits o...  \n",
            "2  senior u.s. republican senator: 'let mr. muell...  \n",
            "3  fbi russia probe helped by australian diplomat...  \n",
            "4  trump wants postal service to charge 'much mor...  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44898"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the df into a training set and a test set\n",
        "df_train, df_test = train_test_split(df, test_size=0.2, shuffle=True)\n"
      ],
      "metadata": {
        "id": "eLCVCRnvB1c6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Function to tokenize documents\n",
        "def tokenize(document):\n",
        "    return re.split(r\"\\W+\", document)\n",
        "\n",
        "# Count words in each class\n",
        "# Initiate dictionaries to store word count for each class\n",
        "real_wordcount = defaultdict(int)\n",
        "fake_wordcount = defaultdict(int)\n",
        "\n",
        "\n",
        "# Initizalize the Variables to count the number of documents in each class\n",
        "real_doccount = 0\n",
        "fake_doccount = 0\n",
        "\n",
        "# Populate the word counts\n",
        "for _, row in df_train.iterrows():\n",
        "    # Tokenize the document into individual words\n",
        "    words = tokenize(row['document'])\n",
        "    # Check if the document is labeled as real or fake\n",
        "    # If true, then increment corresponding variable\n",
        "    if row['RealNews?'] == True:\n",
        "        real_doccount += 1\n",
        "        for word in words:\n",
        "            real_wordcount[word] += 1\n",
        "    # If false\n",
        "    else:\n",
        "        fake_doccount += 1\n",
        "        for word in words:\n",
        "            fake_wordcount[word] += 1\n",
        "\n",
        "# Calculate probabilities with Laplace smoothing\n",
        "# Laplace smoothing is applied by adding 1 to the word count\n",
        "# to avoid zero probability issues, and dividing by the total count of\n",
        "# words in the class plus the vocabulary size\n",
        "\n",
        "# Union the keys of both the dictionaries\n",
        "unique_vocab = set(real_wordcount.keys()).union(set(fake_wordcount.keys()))\n",
        "vocab_size = len(unique_vocab)\n",
        "# Total words in real news\n",
        "total_real_words = sum(real_wordcount.values())\n",
        "# Total words in fake news\n",
        "total_fake_words = sum(fake_wordcount.values())\n",
        "\n",
        "#  Calculate the probability of a word given the class\n",
        "def word_prob(word, real=True):\n",
        "    if real:\n",
        "        return (real_wordcount[word] + 1) / (total_real_words + vocab_size)\n",
        "    else:\n",
        "        return (fake_wordcount[word] + 1) / (total_fake_words + vocab_size)\n",
        "\n",
        "# Document probability given class\n",
        "def document_prob(doc, real=True):\n",
        "    words = tokenize(doc)\n",
        "    # Compute the logarithm of the prior probability of the class\n",
        "    prob = np.log(real_doccount / (real_doccount + fake_doccount)) if real else np.log(fake_doccount / (real_doccount + fake_doccount))\n",
        "    # Add the log probability of each word in the document\n",
        "    for word in words:\n",
        "        prob += np.log(word_prob(word, real))\n",
        "    return prob\n"
      ],
      "metadata": {
        "id": "qzhycU3CB6_p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the lists to store true and predicted labels\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# Iterate the test dataset to make predictions\n",
        "for _, row in df_test.iterrows():\n",
        "    # log probability of the document being real\n",
        "    real_prob = document_prob(row['document'], real=True)\n",
        "    # log probability of the document being fake\n",
        "    fake_prob = document_prob(row['document'], real=False)\n",
        "    # append the labels\n",
        "    y_true.append(row['RealNews?'])\n",
        "    y_pred.append(real_prob > fake_prob)\n",
        "\n",
        "# Evaluate performance\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WycrnpONB-SM",
        "outputId": "7fc2cfca-f186-42b9-9bd5-073c38b6bda2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9514607775477341\n",
            "Recall: 0.9574074074074074\n",
            "F1 Score: 0.9544248298142379\n"
          ]
        }
      ]
    }
  ]
}